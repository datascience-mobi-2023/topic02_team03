{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading /Users/liza/Desktop/Bioinfo Project/amino_acid_genotypes_to_brightness.tsv\n",
      "Dumped amino_acid_genotypes_to_brightness_parsed.tsv with 54025 substitutions and 54024 variants\n"
     ]
    }
   ],
   "source": [
    "#----------GMMA00---------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Set options\n",
    "pd.set_option(\"display.width\", 200)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "\n",
    "# Read data from file\n",
    "file = \"/Users/liza/Desktop/Bioinfo Project/amino_acid_genotypes_to_brightness.tsv\"\n",
    "print(\"\\nReading\", file)\n",
    "d = pd.read_csv(file, sep=\"\\t\", header=None, skiprows=1, names=[\"seq\", \"N\", \"signal\", \"sd\"])\n",
    "\n",
    "# Split mutations\n",
    "mut_list = d[\"seq\"].str.split(\":\")\n",
    "mut_list = mut_list.drop(index=0)\n",
    "# Remove leading \"S\" from substitutions\n",
    "mut_list = mut_list.apply(lambda x: [m[1:] for m in x])\n",
    "\n",
    "# Combine substitutions into a single string\n",
    "subst = mut_list.apply(lambda x: \":\".join(x))\n",
    "#wieder wie vorher zusammenschreiben, nur ohne S vor jeder Mut\n",
    "subst[0] = \"WT\"\n",
    "\n",
    "# Create data frame\n",
    "df = pd.DataFrame({\"variant\": subst, \"bright\": d[\"signal\"], \"n_syn\": d[\"N\"], \"std\": d[\"sd\"]})\n",
    "\n",
    "# Write data to file\n",
    "outfile = \"amino_acid_genotypes_to_brightness_parsed.tsv\"\n",
    "df.to_csv(outfile, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "print(f\"Dumped {outfile} with {len(subst)} substitutions and {len(mut_list)} variants\")\n",
    "\n",
    "#bereitet die original datei vor, indem es die erste zeile (wt) anders macht und die S entfernt und einen neuen df macht"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T14:15:31.644596Z",
     "start_time": "2023-06-14T14:15:30.427291Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading amino_acid_genotypes_to_brightness_parsed.tsv\n",
      "Making data structures\n",
      "\n",
      "Building subst_mut_indices\n",
      "done building subst_mut_indices\n",
      "Successfully generated indexed data structures of 54024 variants carrying 1879 unique substitutions\n",
      "Saved gmma_structured.csv\n"
     ]
    }
   ],
   "source": [
    "#----------GMMA01---------------\n",
    "import numpy as np\n",
    "# es wird mit dem output des Codes von GMMA00 weitergearbeitet\n",
    "file = \"amino_acid_genotypes_to_brightness_parsed.tsv\"\n",
    "\n",
    "print(\"Reading\", file)\n",
    "\n",
    "# Read data\n",
    "try:\n",
    "    d = pd.read_table(file, header=None)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found.\")\n",
    "    exit()\n",
    "\n",
    "# Check if the first row is a label\n",
    "if isinstance(d.iloc[0, 0], str):\n",
    "    wt_seq = \"\"\n",
    "else:\n",
    "    wt_seq = d.iloc[0, 0].lower()\n",
    "\n",
    "# Remove first row (wild type or label)\n",
    "d = d.iloc[1:]\n",
    "\n",
    "# Wild-type average log brightness, number of WT measurements, and standard deviation\n",
    "d.columns = [\"seq\", \"N\", \"signal\", \"sd\"]\n",
    "wt = d.iloc[0].copy()\n",
    "wt[\"seq\"] = \"\"\n",
    "\n",
    "print(\"Making data structures\")\n",
    "\n",
    "# Settings\n",
    "settings = {}\n",
    "settings[\"taa_letters\"] = 1\n",
    "\n",
    "# Per mutant data\n",
    "def split_mut_list(seq):\n",
    "    if \":\" in seq:\n",
    "        return seq.split(\":\")\n",
    "    else:\n",
    "        return [seq]\n",
    "\n",
    "mut_list = d[\"seq\"].fillna('').apply(split_mut_list)\n",
    "\n",
    "mutant = pd.DataFrame(\n",
    "    {\n",
    "        \"i\": range(1, len(mut_list) + 1),\n",
    "        \"signal\": d[\"signal\"],\n",
    "        \"N_sub\": [len(sub) for sub in mut_list],\n",
    "        \"N_obs\": d[\"N\"],\n",
    "        \"sd_obs\": d[\"sd\"],\n",
    "    }\n",
    ")\n",
    "mutant.index = [\"mut{:05d}\".format(i) for i in range(1, len(mut_list) + 1)]\n",
    "mutant[\"subst\"] = mut_list.str.join(\":\")\n",
    "\n",
    "# Per substitution data\n",
    "subst_table = pd.Series(mut_list.explode()).value_counts()\n",
    "nsubst = len(subst_table)\n",
    "#die Positionen zählen\n",
    "#subst_table = Positionen der Mutationen\n",
    "## ?Zählen wieviele Mutationen?\n",
    "\n",
    "# Make data structure of substitutions\n",
    "subst = pd.DataFrame({\"subst_table\": subst_table})\n",
    "subst[\"resi\"] = 0\n",
    "subst[\"taa\"] = \"\"\n",
    "subst[\"obs\"] = subst[\"subst_table\"]\n",
    "subst[\"signal\"] = pd.NA\n",
    "subst.index.name = \"Var1\"\n",
    "subst.reset_index(inplace=True)\n",
    "subst = subst.sort_values(\"Var1\")\n",
    "subst[\"i\"] = range(1, nsubst + 1)\n",
    "\n",
    "# Assign residue and taa values\n",
    "for si in range(1, nsubst + 1):\n",
    "    m = subst[\"Var1\"].iloc[si - 1]\n",
    "    if m and m != '':\n",
    "        subst.at[si, \"resi\"] = m[1:-settings[\"taa_letters\"]]\n",
    "        subst.at[si, \"taa\"] = m[-settings[\"taa_letters\"]:]\n",
    "#die\n",
    "# Per residue data\n",
    "residue = pd.DataFrame(list(wt_seq), columns=[\"wt\"])\n",
    "residue[\"subst\"] = \"\"\n",
    "residue[\"N_mut\"] = pd.NA\n",
    "\n",
    "# Assign substitutions\n",
    "for ri in range(1, len(residue) + 1):\n",
    "    residue.at[ri, \"subst\"] = subst.loc[subst[\"resi\"] == ri, \"taa\"].str.cat(sep=\"\")\n",
    "\n",
    "    si = subst.index[subst[\"resi\"] == ri]\n",
    "    residue.at[ri, \"N_mut\"] = subst.loc[si, \"obs\"].sum()\n",
    "\n",
    "# Build index translation lists between data frames\n",
    "res_mut_indices = [mutant.index[mutant[\"subst\"].str.contains(\":{}:\".format(i))] for i in range(1, len(residue) + 1)]\n",
    "mut_subst_indices = [subst.index[subst[\"Var1\"].isin(sub)] for sub in mut_list]\n",
    "subst_mut_indices = []\n",
    "for si in range(nsubst):\n",
    "    indices = np.where(mutant[\"subst\"].str.contains(\":{}:\".format(subst.loc[si, \"Var1\"])))[0]\n",
    "    subst_mut_indices.append(indices)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Building subst_mut_indices\")\n",
    "print(\"done building subst_mut_indices\")\n",
    "nsubst = len(subst_mut_indices)\n",
    "\n",
    "\n",
    "print(\"Successfully generated indexed data structures of {} variants carrying {} unique substitutions\".format(\n",
    "    len(mut_list), nsubst))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def save_data_to_csv(settings, wt, mut_list, mutant, subst, residue, mut_subst_indices, subst_mut_indices, res_mut_indices, file=\"gmma_structured.csv\"):\n",
    "    data = {\n",
    "        \"settings\": pd.DataFrame(settings, index=[0]),\n",
    "        \"wt\": wt,\n",
    "        \"mut_list\": pd.DataFrame({\"seq\": mut_list}),\n",
    "        \"mutant\": mutant,\n",
    "        \"subst\": subst,\n",
    "        \"residue\": residue,\n",
    "        \"mut_subst_indices\": pd.DataFrame({\"mut_subst_indices\": mut_subst_indices}),\n",
    "        \"subst_mut_indices\": pd.DataFrame({\"subst_mut_indices\": subst_mut_indices}),\n",
    "        \"res_mut_indices\": pd.DataFrame({\"res_mut_indices\": res_mut_indices})\n",
    "    }\n",
    "\n",
    "    with open(file, \"w\") as f:\n",
    "        for key, value in data.items():\n",
    "            f.write(f\"---{key}---\\n\")\n",
    "            value.to_csv(f, index=False)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    print(f\"Saved {file}\")\n",
    "\n",
    "# Beispielaufruf\n",
    "save_data_to_csv(settings, wt, mut_list, mutant, subst, residue, mut_subst_indices, subst_mut_indices, res_mut_indices, file=\"gmma_structured.csv\")\n",
    "\n",
    "#hat glaube ich geklappt: 54024 (im csv file: eine Zeile head und eine wt) variants mit 1879 (stimmt) substitutions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T14:54:21.117252Z",
     "start_time": "2023-06-14T14:53:56.289642Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mutant'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/DMSproject/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/anaconda3/envs/DMSproject/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/DMSproject/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'mutant'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 26\u001B[0m\n\u001B[1;32m     22\u001B[0m data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgmma_structured.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Assign number of rows\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m nmut \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmutant\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     27\u001B[0m nsubst \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubst\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     28\u001B[0m nres \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresidue\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/DMSproject/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/anaconda3/envs/DMSproject/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'mutant'"
     ]
    }
   ],
   "source": [
    "#----------GMMA02---------------\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set R environment options\n",
    "options = {\n",
    "    \"width\": 120,\n",
    "    \"digits\": 3,\n",
    "    \"stringsAsFactors\": False\n",
    "}\n",
    "\n",
    "# Analysis settings----------------------\n",
    "RT = 1.985*300/1000.0          # RT value\n",
    "unit_RT = \"kcal/mol (at 300 K)\" # RT unit\n",
    "dG_wt = -2.8\n",
    "# dG_wt_input = dG_wt\n",
    "\n",
    "#--------------------------------------\n",
    "\n",
    "# Load data from file\n",
    "data = pd.read_csv(\"gmma_structured.csv\", sep='\\t')\n",
    "\n",
    "\n",
    "# Assign number of rows\n",
    "nmut = data[\"mutant\"].shape[0]\n",
    "nsubst = data[\"subst\"].shape[0]\n",
    "nres = data[\"residue\"].shape[0]\n",
    "\n",
    "\n",
    "# Initialize cp list\n",
    "cp = {\"dG_wt\": dG_wt}\n",
    "\n",
    "# Assign active column in mutant data frame\n",
    "cp[\"B_mid\"] = data[\"mutant\"][\"signal\"].quantile(0.5)\n",
    "data[\"mutant\"][\"active\"] = np.where(data[\"mutant\"][\"signal\"] < cp[\"B_mid\"], 0, 1)\n",
    "\n",
    "# Assign active and inactive counts in subst data frame\n",
    "active_cut = data[\"mutant\"][\"active\"].mean() + 2 * data[\"mutant\"][\"active\"].std()\n",
    "inactive_cut = active_cut\n",
    "data[\"subst\"][\"active\"] = np.where(data[\"mutant\"][\"active\"] == 1, 1, 0)\n",
    "data[\"subst\"][\"inactive\"] = np.where(data[\"mutant\"][\"active\"] == 0, 1, 0)\n",
    "active_count = data[\"subst\"].groupby(\"subst\")[\"active\"].sum()\n",
    "inactive_count = data[\"subst\"].groupby(\"subst\")[\"inactive\"].sum()\n",
    "data[\"subst\"] = pd.merge(data[\"subst\"], active_count, on=\"subst\")\n",
    "data[\"subst\"] = pd.merge(data[\"subst\"], inactive_count, on=\"subst\")\n",
    "\n",
    "# Assign active and inactive counts in residue data frame\n",
    "data[\"residue\"][\"active\"] = data[\"subst\"].groupby(\"residue\")[\"active\"].sum()\n",
    "data[\"residue\"][\"inactive\"] = data[\"subst\"].groupby(\"residue\")[\"inactive\"].sum()\n",
    "\n",
    "# Clean data for initial fitting\n",
    "data[\"mutant\"][\"init\"] = data[\"mutant\"][\"signal\"]\n",
    "data[\"mutant\"][\"init_m\"] = data[\"mutant\"][\"mutant\"]\n",
    "data[\"subst\"][\"init_m\"] = data[\"subst\"][\"mutant\"]\n",
    "data[\"subst\"][\"init\"] = data[\"subst\"][\"signal\"]\n",
    "\n",
    "# Define exclude_data function\n",
    "def exclude_data(data, condition, message):\n",
    "    count = data.shape[0]\n",
    "    data = data[~condition]\n",
    "    excluded_count = count - data.shape[0]\n",
    "    print(f\"{excluded_count} {message} excluded.\")\n",
    "    return data, excluded_count\n",
    "\n",
    "# Exclude specific data based on conditions\n",
    "data[\"subst\"], excluded_subst = exclude_data(data[\"subst\"], data[\"subst\"][\"si_nonsense\"], \"substitutions with nonsense mutants\")\n",
    "data[\"mutant\"], excluded_mutants = exclude_data(data[\"mutant\"], data[\"mutant\"][\"si_lowobs\"], \"low observed mutants\")\n",
    "data[\"subst\"], excluded_subst_lowact = exclude_data(data[\"subst\"], data[\"subst\"][\"si_lowact\"], \"substitutions with low activity\")\n",
    "\n",
    "# Calculate probability of IFS\n",
    "prob_IFS = data[\"subst\"][\"inactive\"] / (data[\"subst\"][\"inactive\"] + data[\"subst\"][\"active\"])\n",
    "data[\"subst\"][\"log_prob_IFS\"] = np.log10(prob_IFS)\n",
    "\n",
    "# Calculate probability of IF\n",
    "prob_IF = data[\"subst\"][\"active\"] / (data[\"subst\"][\"inactive\"] + data[\"subst\"][\"active\"])\n",
    "data[\"subst\"][\"log_prob_IF\"] = np.log10(prob_IF)\n",
    "\n",
    "# Fit data for linear regression\n",
    "fit = np.polyfit(data[\"subst\"][\"init\"], data[\"subst\"][\"signal\"], 1, full=True)\n",
    "\n",
    "# Calculate dG_wt using linear regression\n",
    "dG_wt_lr = fit[0][1]\n",
    "\n",
    "# Initialize lists for statistics\n",
    "cp[\"nsubst_lowact\"] = []\n",
    "cp[\"nsubst_highact\"] = []\n",
    "cp[\"subst_highact\"] = []\n",
    "cp[\"dG_wt_corr\"] = []\n",
    "\n",
    "# Iteratively adjust dG_wt and perform calculations\n",
    "for i in range(4):\n",
    "    # Identify low and high active substitutions\n",
    "    low_act_cut = data[\"subst\"][\"active\"].quantile(0.25)\n",
    "    high_act_cut = data[\"subst\"][\"active\"].quantile(0.75)\n",
    "    low_act_subst = data[\"subst\"][data[\"subst\"][\"active\"] < low_act_cut]\n",
    "    high_act_subst = data[\"subst\"][data[\"subst\"][\"active\"] > high_act_cut]\n",
    "\n",
    "    # Calculate average signal of low and high active substitutions\n",
    "    low_act_mean = low_act_subst[\"signal\"].mean()\n",
    "    high_act_mean = high_act_subst[\"signal\"].mean()\n",
    "\n",
    "    # Calculate difference in average signal\n",
    "    diff_mean = high_act_mean - low_act_mean\n",
    "\n",
    "    # Update dG_wt\n",
    "    dG_wt = dG_wt_lr + diff_mean\n",
    "\n",
    "    # Exclude substitutions with low activity\n",
    "    data[\"subst\"], excluded_subst_lowact = exclude_data(data[\"subst\"], data[\"subst\"][\"signal\"] < dG_wt, \"substitutions with low activity\")\n",
    "\n",
    "    # Calculate linear regression with updated dG_wt\n",
    "    fit = np.polyfit(data[\"subst\"][\"init\"], data[\"subst\"][\"signal\"], 1, full=True)\n",
    "    dG_wt_lr = fit[0][1]\n",
    "\n",
    "    # Calculate correlation coefficient\n",
    "    corr_coef = np.corrcoef(data[\"subst\"][\"signal\"], data[\"subst\"][\"init\"])[0, 1]\n",
    "\n",
    "    # Update lists with statistics\n",
    "    cp[\"nsubst_lowact\"].append(excluded_subst_lowact)\n",
    "    cp[\"nsubst_highact\"].append(high_act_subst.shape[0])\n",
    "    cp[\"subst_highact\"].append(high_act_subst[\"subst\"].tolist())\n",
    "    cp[\"dG_wt_corr\"].append(corr_coef)\n",
    "\n",
    "# Print final results\n",
    "print(\"Final results:\")\n",
    "print(\"dG_wt:\", dG_wt)\n",
    "print(\"Correlation coefficient:\", corr_coef)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T14:54:41.703667Z",
     "start_time": "2023-06-14T14:54:39.321299Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
